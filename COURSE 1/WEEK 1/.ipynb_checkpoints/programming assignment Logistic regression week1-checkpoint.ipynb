{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def process_tweets(tweet):\n",
    "    #remove the old style retweet text \"RT\"\n",
    "    tweet2 = re.sub( r'^RT[\\s]+' , '' ,tweet)\n",
    "\n",
    "    #remove hyperlinks\n",
    "    tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*' , '' ,      tweet2)\n",
    "\n",
    "    #remove hashtag (only the # sign)\n",
    "    tweet2 = re.sub(r'#' , '' ,tweet2)\n",
    "\n",
    "    #instantiate the tokenizer class\n",
    "    tokenizer = TweetTokenizer  (preserve_case=False,\n",
    "                          strip_handles=True,\n",
    "                          reduce_len = True)\n",
    "\n",
    "    #tokenize tweets\n",
    "    tweet_tokens = tokenizer.tokenize(tweet2)\n",
    "\n",
    "    #importing the english stop words from nltk\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "    tweets_clean = []\n",
    "\n",
    "    for word in tweet_tokens:\n",
    "        if(word not in stopwords_english \n",
    "        and \n",
    "        word not in string.punctuation):\n",
    "            tweets_clean.append(word)\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    #create an empty list to store the stems\n",
    "    tweets_stem = []\n",
    "\n",
    "    for word in tweets_clean:\n",
    "        stem_word = stemmer.stem(word)  \n",
    "        #stemming word\n",
    "        tweets_stem.append(stem_word)\n",
    "    \n",
    "    return tweets_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets , ys):\n",
    "    \"\"\"Build frequencies\n",
    "    input:\n",
    "        tweets : a list of tweets\n",
    "        ys: an mx1 array with the sentiment label of each tweet(either 0 or 1)\n",
    "    output:\n",
    "        freqs: a dictionary mapping each (word,sentiment) pair to its frequency\n",
    "        \"\"\"\n",
    "    \n",
    "    #convert the np array to list since zip needs an iterble\n",
    "    # The squeeze is necessary or the list ends up with  one element\n",
    "    # also note that this is just a NOP if ys is already a list\n",
    "     \n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    #start with an empty dictionary and populate it by looping  over all tweets\n",
    "    # and over all processed words in each tweet\n",
    "    freqs={}\n",
    "\n",
    "    for y , tweet in zip(yslist , tweets):\n",
    "        for word in process_tweets(tweet):\n",
    "            pair =  (word,y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing split\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine positive and negative labels\n",
    "train_y = np.append(np.ones(( len(train_pos),1 )) , np.zeros((len(train_neg),1)),axis =0 )\n",
    "test_y = np.append(np.ones(( len(test_pos),1 )) , np.zeros((len(test_neg),1)),axis =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len (freqs) = 11339\n"
     ]
    }
   ],
   "source": [
    "# create frequency duictionary\n",
    "freqs = build_freqs(train_x,train_y)\n",
    "\n",
    "print(\"type(freqs) = \"+str(type(freqs)))\n",
    "print(\"len (freqs) = \"+str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "# test the function below\n",
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweets(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1.1 sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# code to be submitted\n",
    "def sigmoid(z):\n",
    "    import math\n",
    "    h = 1 / (1 + math.exp(-z) )\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1.2 cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(0) -> log(1) == -inf -> 0\n",
    "# h(z)for ith example if equal to y gives 0\n",
    "# if they are not then log gives a big positive value\n",
    "\n",
    "#lets take y 0.99 and hz as 0\n",
    "-1*( (0.992*np.log(0)) + (1-0.992)(np.log(1-0)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3NLP",
   "language": "python",
   "name": "python3nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
